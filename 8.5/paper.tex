\documentclass{ansarticle-preprint}
%\usepackage{ucs}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
%\usepackage{cite}
\usepackage{anslistings}
\usepackage{multicol}

\usepackage{pgfplots}
\usepackage{pgfplotstable}

\usepackage{fontenc}
\usepackage{graphicx}

\pgfplotsset{compat=1.9}

\newcommand{\specialword}[1]{\texttt{#1}}
\newcommand{\dealii}{{\specialword{deal.II}}}
\newcommand{\pfrst}{{\specialword{p4est}}}
\newcommand{\trilinos}{{\specialword{Trilinos}}}
\newcommand{\aspect}{\specialword{Aspect}}
\newcommand{\petsc}{\specialword{PETSc}}
\newcommand{\cmake}{{\specialword{CMake}}}
\newcommand{\autoconf}{{\specialword{autoconf}}}

%
% Author list -- please add yourself in both places below (in
%                alphabetical order) if you think that your
%                contributions to the last release warrant this
%

\hypersetup{
  pdfauthor={
    Daniel Arndt,
    Wolfgang Bangerth,
    Denis Davydov,
    Timo Heister,
    Luca Heltai,
    Martin Kronbichler,
    Matthias Maier,
    Jean-Paul Pelteret
  },
  pdftitle={The deal.II Library, Version 8.5, 2017},
}

\title{The \dealii{} Library, Version 8.5}

\author[1]{Daniel Arndt}
\affil[1]{Interdisciplinary Center for Scientific Computing,
    Heidelberg University, Im Neuenheimer Feld 205, 69120 Heidelberg, Germany.
    {\texttt{daniel.arndt@iwr.uni-heidelberg.de}}}

\author[2]{Wolfgang Bangerth}
\affil[2]{Department of Mathematics, Colorado State University, Fort
  Collins, CO 80523-1874, USA.
    {\texttt{bangerth@colostate.edu}}}

\author[3]{Denis Davydov}
\affil[3]{Chair of Applied Mechanics, University of
     Erlangen-Nuremberg, Egerlandstr.\ 5, 91058 Erlangen, Germany.
    {\texttt{denis.davydov@fau.de}}}

\author[4]{Timo Heister}
\affil[4]{Mathematical Sciences,
  O-110 Martin Hall,
  Clemson University,
  Clemson, SC 29634, USA.
  {\texttt{heister@clemson.edu}}}

\author[5]{Luca Heltai}
\affil[5]{SISSA,
  International School for Advanced Studies,
  Via Bonomea 265,
  34136, Trieste, Italy.
{\texttt{luca.heltai@sissa.it}}}

\author[6]{Martin Kronbichler}
\affil[6]{Institute for Computational Mechanics,
  Technical University of Munich,
  Boltzmannstr.~15, 85748 Garching, Germany.
  {\texttt{kronbichler@lnm.mw.tum.de}}}

\author[7]{Matthias Maier}
\affil[7]{School of Mathematics,
  University of Minnesota,
  127 Vincent Hall, 206 Church Street SE,
  Minneapolis, MN 55455, USA.
  {\texttt{msmaier@umn.edu}}}

\author[8]{Jean-Paul Pelteret}
\affil[8]{Chair of Applied Mechanics,
  University of Erlangen-Nuremberg,
  Egerlandstr.\ 5,
  91058 Erlangen,
  Germany.
  {\texttt{jean-paul.pelteret@fau.de}}}

\renewcommand{\labelitemi}{--}




\begin{document}
\maketitle

\begin{abstract}
  This paper provides an overview of the new features of the finite element
  library \dealii{} version 8.5.
\end{abstract}


\section{Overview}

\marginpar{Update date}
\dealii{} version 8.5.0 was released March 11, 2017. This paper provides an
overview of the new features of this release and serves as a citable
reference for the \dealii{} software library version 8.5. \dealii{} is an
object-oriented finite element library used around the world in the
development of finite element solvers. It is available for free under the
GNU Lesser General Public License (LGPL) from the \dealii{} homepage at
\url{http://www.dealii.org/}.

The major changes of this release are:
\begin{itemize}
\item The \texttt{CellDataStorage} class provides a mechanism to store
  and communicate user-defined data on each cell. 

\item The \texttt{MappingManifold} class provides mappings between the
  reference cell and a mesh cell that is ``exact'', rather than the
  usual polynomial approximations of a manifold.

\item The \texttt{LinearOperator} class has been extended by a generic
  ``payload'' mechanism that allows the attachment of arbitrary additional
  information to a \texttt{LinearOperator}.

\item A dedicated physics module has been created to provide some standard
  definitions and operations used in continuum mechanics.

\item The \texttt{FE\_Enriched} class implements the operation of
  enriching the finite element space of an underlying element.

\item The \texttt{FESeries} namespace provides expansions of a finite
  element solution in terms of different, hierarchical bases.

\item New tutorial programs step-55, step-56, and step-57; as well as
  updates to step-27, step-37, and step-44.

\item New code gallery programs demonstrating
\marginpar{Isn't the code gallery itself new for 8.5?}
  \begin{enumerate}
    \item[(i)] quasi-static visco-elastic material behavior,
    \item[(ii)] multiphase Navier-Stokes flow,
    \item[(iii)] the evolution of global-scale topography on planetary bodies,
    \item[(iv)] goal-oriented elastoplasticity.
  \end{enumerate}

\item Various improvements for high-order elements, including a switch of
  support points in \texttt{FE\_Q} and \texttt{FE\_DGQ} to Gauss-Lobatto
  support points, stable evaluation of high-order Legendre polynomials, and
  several bugfixes for high-order polynomial mappings defined through the
  \texttt{MappingQ} class.


\item Static code analyzers are valuable tools to improve
  and maintain the quality of the code in our library in addition to build and
  regression tests for a variety of setups using
  \href{https://cdash.kyomu.43-1.org/index.php?project=deal.II}{CDash}.
  This release was tested with
  \href{http://cppcheck.sourceforge.net/}{Cppcheck},
  \href{https://www.viva64.com/en/pvs-studio/}{PVS-Studio} and
  \href{https://scan.coverity.com/}{Coverity-Scan}.

  \item More than 230 other features and bugfixes.
\end{itemize}
The more important ones of these changes will be detailed in the
following section.  Information on how to cite \dealii{} is provided
in Section \ref{sec:cite}.



\section{Significant changes to the library}

This release of \dealii{} contains a number of large and significant changes
that will be discussed in the following sections. It of course also contains a
vast number of smaller changes and added functionality; the details of these
can be found
\href{https://www.dealii.org/8.5.0/doxygen/deal.II/changes_between_8_4_and_8_5.html}{in
the file that lists all changes for this release}, see \cite{changes85}.
(The file is also linked to from the web site of each release as well as
the release announcement.)


\subsection{The \texttt{CellDataStorage} class and friends}

The \texttt{CellDataStorage} class is an integrated mechanism to
store user-defined data within each cell, such as a coefficient at each quadrature point.
Although the same was previously achieved through the use
of a cell \texttt{user\_pointer}, it required users to manage this data
themselves, including transfer of this data if ownership of a cell is
transferred from one processor to another in parallel
computations. Instead, this data is now treated as a first-class
citizen in \dealii{}.

\texttt{CellDataStorage} can work with arbitrary kinds of data defined
to live on a cell as long as the corresponding data type implements a
certain interface. As an example,
the abstract \texttt{TransferableQuadraturePointData} class provides
a generic interface to facilitate several low-level operations
that were previously tedious or technically challenging to implement.
\marginpar{Denis: It is not clear to me how \texttt{CellDataStorage} and
  \texttt{p::d::ContinuousQuadratureDataTransfer} relate to each
  other. Can you clarify the paragraph?}
For instance, the
\texttt{parallel::distributed::ContinuousQuadratureDataTransfer} class
assists in the transfer of arbitrary data (that is continuous within a
cell) stored at quadrature points when performing $h$-adaptive refinement of
\texttt{parallel::distributed::Triangulation}. Not only does it perform an
$L^2$-projection of the specified user data between quadrature
points, but it also ships the data automatically between MPI processes.

\subsection{The \texttt{MappingManifold} class}

The \texttt{MappingManifold} class implements the functionality
of the \texttt{Mapping} interface for \emph{manifold conforming}
mappings. In other words, instead of using polynomial approximations
of the objects that describe the boundaries (or interiors) of cells,
this class computes the transformation between the
reference and real cell by exploiting the geometrical information
coming from the underlying \texttt{Manifold} object.

When using this class,
quadrature points lie on the \textit{exact}
geometrical objects, and tangent and normal vectors computed
are tangent and normal to the underlying geometry. This is
in contrast with the \texttt{MappingQ} and \texttt{MappingQGeneric}
classes, which approximate the geometry using a polynomial of some
order, and then compute the normals and tangents using the
approximated surface.

The class currently only implements the information that relates to
the mapping itself, as well to its derivatives (such as the Jacobian
of the mapping, or the determinant thereof). Information related to
higher order derivatives -- such as the Hessian of the mapping -- will
result in an exception.


\subsection{Extension of the \texttt{LinearOperator} class}

We have extended the \texttt{LinearOperator} class by a generic
``payload'' mechanism that allows for the attachment of arbitrary additional
information to a \texttt{LinearOperator}. This was achieved by introducing
a generic \texttt{Payload} base class. The main use case of the new
mechanism is to extend the \texttt{LinearOperator} class to seamlessly
exploit the native features and operations offered by external linear
algebra libraries. We have thus developed a \texttt{TrilinosPayload} class
that provides full support for the suite of {\trilinos} parallel iterative
solvers and preconditioners.

A particularly interesting case is the construction of an
\texttt{inverse\_operator}. Whereas previously only \dealii's built-in solvers
were compatible with this operator, one can now also select those
offered by {\trilinos}. This has been achieved by using
the \texttt{Epetra\_Operator} as the basis for the
\texttt{TrilinosPayload}, for which the result of standard and composite
operations involving forward (\texttt{Apply()}) and inverse
(\texttt{ApplyInverse()}) matrix-vector multiplication are collated using
lambda functions.

We envisage that, in the future, similar extensions can be implemented for the {\petsc}
iterative solvers.

Another additional in this release related to the \texttt{LinearOperator} suite is the definition
of a \texttt{schur\_complement} operator and its associated condensation
and post-processing \texttt{PackagedOperation}s. An operator representing
the Schur complement of a block system can be declared and, through the
delayed evaluation offered by \texttt{PackagedOperation}s, reused on any
number of vector systems.

\subsection{The physics module}
\label{sec:physics}

We have created a dedicated physics module to facilitate the
implementation of functions and classes that relate to continuum mechanics,
physical fields and material constitutive laws. To date, it includes
transformations of scalar or tensorial quantities between any two
configurations (by user-specification of a linear map $\mathbf{F}$), and some 
definitions typically utilized in both linear and finite-strain nonlinear 
elasticity.

The \verb!Physics::Transformations! namespace offers push-forward and
pull-back operations in the context of contravariant, covariant and Piola
transformations, as well as rotation operations for the Euclidean space. 
Although these transformations are defined in a general manner, one typical
use of them in finite-strain elasticity would be the determination of the 
Cauchy stress tensor $\boldsymbol{\sigma} = \boldsymbol{\sigma}\left(\mathbf{x}\right)$ 
defined at a spatial position $\mathbf{x} \in \mathcal{B}$ from its
fully referential counterpart, namely the Piola-Kirchhoff stress tensor 
$\mathbf{S} = \mathbf{S}\left(\mathbf{X}\right)$ computed at the material 
coordinate $\mathbf{X} \in \mathcal{B}_{0}$.
By choosing
$\mathbf{F} \left(\mathbf{X}\right) = \dfrac{\partial \mathbf{x}\left(\mathbf{X}\right)}{\partial \mathbf{X}}$,
this is achieved through the action of the Piola push-forward
$\boldsymbol{\sigma} = \dfrac{1}{\det \mathbf{F}} \, \mathbf{F} \cdot \mathbf{S} \cdot \mathbf{F}^{T}$.

In the \verb!Physics::Elasticity::Kinematics! namespace, a selection of
deformation, strain and strain rate tensors are defined. The
\verb!Physics::Elasticity::StandardTensors! class provides some frequently
used second and fourth order metric tensors, and defines a number of
referential and spatial projection operators and tensor derivatives that
are commonly required in the definition of material laws.


The updated step-44 tutorial program demonstrates the
use of the physical module in the context of a solid mechanics problem.


\subsection{Scalability of geometric multigrid framework}

For the new release, the geometric multigrid facilities in \dealii{} have been
thoroughly overhauled regarding their scalability on large-scale parallel
systems. During this process, a geometric multigrid implementation based on
the fast matrix-free kernels from \cite{KronbichlerKormann2012} has been
benchmarked on up to 147,456 cores. The fast matrix-vector products revealed
several scalability bottlenecks in the other multigrid components, including
unnecessary inner products inside the Chebyshev smoother and
${\mathcal O}(n_\text{levels})$ global communication steps during the
restriction process rather than the single unavoidable global communication
step inherent to going to the coarsest grid and the coarse solve. We
implemented new
matrix-free transfer implementations called \texttt{MGTransferMatrixFree}
that can replace the matrix-based \texttt{MGTransferPrebuilt} class
for tensor product elements. Besides better scalability than the Trilinos
Epetra matrices underlying the latter, the matrix-free transfer is also a much
faster for high-order elements with a complexity per degree of freedom of
$\mathcal O(d p)$ in the polynomial degree $p$ in $d$ dimensions rather than
$\mathcal O(p^d)$ for the matrices.

\begin{figure}
\pgfplotstableread{
nprocs     fem256k    fem2m     fem16m    fem128m  fem1g    fem8g
16         0.640934   4.97684   nan       nan      nan      nan
32         0.325741   2.51771   nan       nan      nan      nan
64         0.1645     1.2823    nan       nan      nan      nan
128        0.090898   0.658832  5.00366   nan      nan      nan
256        0.059922   0.339999  2.56216   nan      nan      nan
512        0.0455449  0.176482  1.29986   nan      nan      nan
1024       0.0368049  0.099691  0.67364   6.48155  nan      nan
2048       0.0348921  0.069573  0.356066  2.59601  nan      nan
4096       0.0367949  0.056833  0.19293   1.3251   nan      nan
8192       0.033958   0.045350  0.110485  0.790214 5.50143  nan
16384      0.0379629  0.049351  0.099904  0.424692 2.81479  nan
32768      0.0461671  0.051276  0.077546  0.229114 1.53091  nan
65536      0.0466189  0.058941  0.075194  0.127353 0.819    6.2909
147456     nan        nan       nan       0.087949 0.43213  2.90856
}\scalinglarge
\pgfplotstableread{
nprocs    newdg256k    newdg2m   newdg16m olddg256k  olddg2m   olddg16m
28        1.4398       12.2014   nan      1.458725   12.25674  nan
56        0.6987        6.2015   nan      0.721993   6.266567  nan
112       0.3352        3.1782   nan      0.353412   3.263585  nan
224       0.1888        1.5687   12.8235  0.183643   1.611967  13.03189
448       0.0853        0.7686   6.5649   0.105388   0.805367  6.700762
896       0.0478        0.3537   3.3685   0.063270   0.383875  3.446427
1792      0.0317        0.1717   1.7061   0.046065   0.199738  1.762310
3584      0.0235        0.1079   0.8580   0.042032   0.123113  0.902782
7168      0.0207        0.0668   0.4328   0.037678   0.091822  0.462007
14336     0.0183699     0.045095 0.23276  0.038804   0.071644  0.288911
}\scalingHSW
\centering
\definecolor{gnuplot@green}{RGB}{0,158,115}
\begin{tikzpicture}
    \begin{loglogaxis}[
      title style={at={(0.5,0.965)},anchor=north,draw=black,fill=white,font=\scriptsize\bf},
      title={strong and weak scaling, continuous $\mathcal Q_3$ elements},
      width=0.52\textwidth,
      height=0.5\textwidth,
      xlabel={Number of cores},
      ylabel={Solver time [s]},
      xtick={32,128,512,2048,8192,32768,147456},
      xticklabels={32,128,512,2048,8192,32k,147k},
      tick label style={font=\scriptsize},
      label style={font=\scriptsize},
      legend style={font=\scriptsize},
      legend pos=south west,
      ymin=5e-3, ymax=15,
      xmin=8, xmax=147456,
      grid
      ]
      \addplot table[x={nprocs}, y={fem8g}] {\scalinglarge};
      \addlegendentry{8B cells};
      \addplot table[x={nprocs}, y={fem1g}] {\scalinglarge};
      \addlegendentry{1B cells};
      \addplot table[x={nprocs}, y={fem128m}] {\scalinglarge};
      \addlegendentry{128M cells};
      \addplot table[x={nprocs}, y={fem16m}] {\scalinglarge};
      \addlegendentry{16M cells};
      \addplot[gnuplot@green,mark=diamond*,mark options={fill=gnuplot@green!40}] table[x={nprocs}, y={fem2m}] {\scalinglarge};
      \addlegendentry{2M cells};
      \addplot[dashed,black] coordinates {
        (8,10)
        (147456,5/9168)
      };
      \addlegendentry{linear scaling};
      \addplot[dashed,black] coordinates {
        (16,8*5)
        (147456,8*5/9168)
      };
      \addplot[dashed,black] coordinates {
        (16,64*5)
        (147456,64*5/9168)
      };
      \addplot[dashed,black] coordinates {
        (16,5*512)
        (147456,5*512/9168)
      };
      \addplot[dashed,black] coordinates {
        (16,5*4096)
        (147456,5*4096/9168)
      };
    \end{loglogaxis}
  \end{tikzpicture}
  \begin{tikzpicture}
    \begin{loglogaxis}[
      title style={at={(1,0.965)},anchor=north east,draw=black,fill=white,font=\scriptsize\bf},
      title={discontinuous $\mathcal Q_3$ elements},
      width=0.48\textwidth,
      height=0.5\textwidth,
      xlabel={Number of cores},
      xtick={56,224,896,3584,14336},
      xticklabels={56,224,896,3584,14336},
      tick label style={font=\scriptsize},
      label style={font=\scriptsize},
      legend style={font=\scriptsize},
      legend pos=south west,
      xmin=28, xmax=14336,
      ymin=5e-3, ymax=15,
      grid
      ]
      \addplot[blue,mark=*,densely dashed] table[x={nprocs}, y={olddg16m}] {\scalingHSW};
      \addlegendentry{old, 16M cells};
      \addplot[blue,mark=o] table[x={nprocs}, y={newdg16m}] {\scalingHSW};
      \addlegendentry{new, 16M cells};
      \addplot[red,mark=square*,densely dashed] table[x={nprocs}, y={olddg2m}] {\scalingHSW};
      \addlegendentry{old, 2M cells};
      \addplot[red,mark=square] table[x={nprocs}, y={newdg2m}] {\scalingHSW};
      \addlegendentry{new, 2M cells};
      \addplot[gnuplot@green,mark=diamond*,densely dashed] table[x={nprocs}, y={olddg256k}] {\scalingHSW};
      \addlegendentry{old, 256k cells};
      \addplot[gnuplot@green,mark=diamond] table[x={nprocs}, y={newdg256k}] {\scalingHSW};
      \addlegendentry{new, 256k cells};
    \end{loglogaxis}
  \end{tikzpicture}
  \caption{Scaling of \dealii{}'s geometric multigrid algorithms on
    SuperMUC. Each line corresponds to a strong scaling experiment,
    increasing the number of processor cores for a fixed-size
    problem. Comparing corresponding data points on different lines
    yields weak scaling information.}
\label{fig:scaling_mg}
\end{figure}

The scalability of the improved geometric multigrid framework is shown in
Fig.~\ref{fig:scaling_mg}, including a combined strong and weak scaling plot
in the left panel using continuous $\mathcal Q_3$ elements with 57~million to
232~billion degrees of freedom for discretizing the Laplacian. Along each
line, the same problem size is solved with an increasing number of cores,
whereas different lines are a factor of eight apart and always start at
3.5~million degrees of freedom per core with an absolute performance of around
650,000 degrees of freedom per core and second. Almost ideal scalability down
to approximately 0.1~seconds can be observed also on 147k~cores. The right
panel of Fig.~\ref{fig:scaling_mg} shows the effect of the aforementioned
algorithmic improvements on a setup with discontinuous DG elements, clearly
improving the latency of the multigrid V-cycle.

The updated step-37 tutorial
programs presents the updated algorithms and the MPI-parallel multigrid
setting with matrix-free operator evaluation.



\subsection{Matrix-free operators}

In order to facilitate the usage of matrix-free methods, a
\verb!MatrixFreeOperator::Base! class has been introduced, implementing
functionality for matrix-vector products and the necessary operations
for the interface residuals for multigrid on adaptively refined meshes
(see \cite{JanssenKanschat2011}). Furthermore, the class is compatible
with the linear operator framework and provides an interface to a Jacobi
preconditioner. Derived classes only need to implement the
\verb!apply_add()! method that is used in the \verb!vmult()! functions, and
a method to compute the diagonal entries of the underlying matrix. The
\verb!MatrixFreeOperator! namespace contains implementations of
\verb!MatrixFreeOperators::LaplaceOperator! and
\verb!MatrixFreeOperators::MassOperator!.

The updated step-37 tutorial
program makes use of these facilities and explains their usage in detail.
Using the matrix-free mass operator, \verb!VectorTools::project! has become
much faster than the previous matrix-based approach for elements supported
by \verb!MatrixFree! and also works for parallel computations based on MPI.


\subsection{The \texttt{FE\_Enriched} class}

The \verb!FE_Enriched! finite element implements a partition of unity
finite element method (PUM) by Babuska and Melenk which enriches a standard
finite element with an enrichment function multiplied with another (usually
linear) finite element. This allows including 
a priori knowledge about the partial differential equation being solved
in the finite element space,
which in turn improves the local approximation properties of the spaces.
Programs can also use enriched and non-enriched finite elements in
different parts of the domain.

The
\verb|DoFTools::make_hanging_node_constraints()| function can automatically
make the resulting space $C^0$ continuous. The existing \verb|SolutionTransfer|
class can be used to transfer the solution during $h$\,-adaptive refinement
from a coarse to a fine mesh under the condition that all child elements
are also enriched.

\subsection{The \texttt{FESeries} namespace}

The \verb|FESeries| namespace offers functions to calculate expansion
series of the solution on the reference element. Coefficients of expansion
are often used to estimate local smoothness of the underlying finite
element field to decide on a $h$- or $p$-adaptive refinement strategy.
Specifically, \verb|FESeries::Legendre| calculates expansion of a
scalar finite element
field into series of Legendre functions on the reference element, whereas
\verb|FESeries::Fourier| calculates Fourier coefficients. Programs
using this functionality have to
specify the required number of coefficients in each direction as well as
provide a collection of finite elements and quadrature rules; these will be
used for the calculation of the transformation matrices.

The updated step-27 tutorial program demonstrates the
use of \verb|FESeries::Fourier|.

\subsection{New and updated tutorial programs}

In addition to the update tutorial programs mentioned in the previous
section, this release of \dealii{} includes three new tutorials:
\begin{itemize}
 \item {\bf step-55} explains how to solve the Stokes 
 equations efficiently in parallel. It is a good introduction to solving
 systems of PDEs in parallel, discusses optimal block 
 preconditioners, and demonstrates other aspects like error computation.
 Inverses of individual blocks of the linear system are approximated with an algebraic 
 multigrid preconditioner.
 
 \item {\bf step-56} shows how to apply geometric multigrid
 preconditioners on a subset of a system of PDEs. The problem solved here is the 
 Stokes equations, like in step-55.
 
 \item {\bf step-57} solves the stationary Navier-Stokes equations.
 The nonlinear system is solved using Newton's method on a sequence of adaptively refined
 grids. The preconditioner is again built on a block factorization of the saddle point
 system like in step-55 and step-56, but the non-symmetric terms stemming from the
 nonlinear convective part requires more sophisticated solvers. The benchmark problem,
 flow in the 2d lid-driven cavity, requires a continuation method for high Reynold's 
 numbers.
 \end{itemize}


\subsection{Incompatible changes}

The 8.5 release includes around 20
\href{https://www.dealii.org/developer/doxygen/deal.II/changes_between_8_4_and_8_5.html}{
incompatible changes}; see \cite{changes85}. The majority of these changes
should not be visible to typical user codes; some remove previously
deprecated classes and functions, and the majority change internal
interfaces that are not usually used in external applications. However, three
incompatible changes are worth mentioning:
\begin{itemize}
  \item High-order Lagrange elements, both continuous \verb!FE_Q! and
    discontinuous \verb!FE_DGQ! types, now use the nodal points of the
    Gauss-Lobatto quadrature formula as support points, rather than the
    previous equidistant ones. For cubic polynomials and higher, the point
    distribution has thus changed and, consequently, the entries in
    solution vectors will be different compared to previous
    versions of \dealii{}. Note, however, that using the Gauss-Lobatto points as nodal
    points results in a much more stable interpolation, including better
    iteration counts in most iterative solvers.
  \item
    The library no longer instantiates template classes with \texttt{long
    double}. These were rarely used, but took up a significant
    fraction of compile and link time, as well as library
    size. Application programs can, however, still instantiate all
    template classes with \texttt{long
    double} as long as they include the corresponding \texttt{.templates.h}
    header files.
  \item
    The \texttt{ParameterGUI} has been moved to a separate repository.
\end{itemize}



\section{How to cite \dealii{}}\label{sec:cite}

In order to justify the work the developers of \dealii{} put into this
software, we ask that papers using the library reference one of the
\dealii{} papers. This helps us justify the effort we put into it.

There are various ways to reference \dealii{}. To acknowledge the use of the
current version of the library, \textbf{please reference the present document}. For up
to date information and bibtex snippets for this document see:
\begin{center}
 \url{https://www.dealii.org/publications.html}
\end{center}

% \begin{minipage}{0.9\textwidth}%no page break in here please
% \begin{verbatim}
% @article{dealII82,
%   title = {The {\tt deal.{I}{I}} Library, Version 8.2},
%   author = {W. Bangerth and T. Heister and L. Heltai
%    and G. Kanschat and M. Kronbichler and M. Maier
%    and B. Turcksin and T. D. Young},
%   journal = {preprint},
%   year = {2015},
% }
% \end{verbatim} %  journal = {arXiv preprint \url{http://arxiv.org/abs/TODO}},
% \end{minipage}

The original \texttt{\dealii{}} paper containing an overview of its
architecture is \cite{BangerthHartmannKanschat2007}. If you rely on specific
features of the library, please consider citing any of the following:
\begin{itemize}
 \item For geometric multigrid: \cite{Kanschat2004,JanssenKanschat2011};
 \item For distributed parallel computing: \cite{BangerthBursteddeHeisterKronbichler11};
 \item For $hp$ adaptivity: \cite{BangerthKayserHerold2007};
  \item For $PUM$ and enrichment of the FE space: \cite{Davydov2016};
 \item For matrix-free and fast assembly techniques:
   \cite{KronbichlerKormann2012};
 \item For computations on lower-dimensional manifolds:
   \cite{DeSimoneHeltaiManigrasso2009};
 \item For integration with CAD files and tools:
   \cite{HeltaiMola2015};
 \item For \texttt{LinearOperator} and \texttt{PackagedOperation} facilities:
   \cite{MaierBardelloniHeltai-2016-a,MaierBardelloniHeltai-2016-b}.
 \item For uses of the \texttt{WorkStream} interface:
   \cite{TKB16}.
\end{itemize}

\dealii{} can interface with many other libraries:
\begin{multicols}{2}
\begin{itemize}
\item ARPACK \cite{arpack}
\item BLAS, LAPACK
\item GSL \cite{gsl2016}
\item HDF5 \cite{hdf5}
\item METIS \cite{karypis1998fast}
\item MUMPS \cite{ADE00,MUMPS:1,MUMPS:2,mumps-web-page}
\item muparser \cite{muparser-web-page}
\item NetCDF \cite{rew1990netcdf}
\item OpenCASCADE \cite{opencascade-web-page}
\item p4est \cite{p4est}
\item PETSc \cite{petsc-user-ref,petsc-web-page}
\item SLEPc \cite{Hernandez:2005:SSF}
\item Threading Building Blocks \cite{Rei07}
\item Trilinos \cite{trilinos,trilinos-web-page}
\item UMFPACK \cite{umfpack}
\end{itemize}
\end{multicols}
Please consider citing the appropriate references if you use interfaces to these
libraries.

Older releases of \dealii{} can be cited as \cite{dealII80,dealII81,dealII82,dealII83,dealII84}.

\nocite{BangerthKanschat1999}

\section{Acknowledgments}

\dealii{} is a world-wide project with dozens of contributors around the
globe. Other than the authors of this paper, the following people contributed code to
this release:\\
%
% get this from the changes/*/* files using the command listed in the
% release-tasks paper and remove the authors of this paper
%
Rajat  Arora,
Mauro  Bardelloni,
Conrad  Clevenger,
Sam  Cox,
Juliane  Dannberg,
Ren{\'e}  Gassm{\"o}ller,
Joscha  Gedicke,
Sebastian  Gonzalez-Pintor,
Ryan  Grove,
Michael  Harmon,
Daniel  Jodlbauer,
Guido  Kanschat,
Justin  Kauffman,
Paul  Kuberry,
Dustin  Kumor,
Konstantin  Ladutenko,
Andrew  McBride,
Mathias  Mentler,
Andrea  Mola,
Dragan  Nikolic,
Vaibhav  Palkar,
Spencer  Patty,
Jonathan  Perry-Houts,
Giuseppe  Pitton,
Ce  Qin,
Jonathan  Robey,
Mayank  Sabharwal,
Ali  Samii,
Alberto  Sartori,
Daniel  Shapero,
Martin  Steigemann,
Jihuan  Tian,
Jaeryun  Yim,
Toby  Young,
Zhao  Liang.

Their contributions are much appreciated!


\bigskip

\dealii{} and its developers are financially supported through a
variety of funding sources:

\marginpar{Add your funding here as appropriate}
D.~Arndt was supported by the German Research Foundation (DFG) under the
project ``High-order discontinuous Galerkin for the exa-scale'' (ExaDG) within the
priority program ``Software for Exascale Computing'' (SPPEXA).

W.~Bangerth was partially
supported by the National Science Foundation under award OCI-1148116
as part of the Software Infrastructure for Sustained Innovation (SI2)
program; and by the Computational Infrastructure in Geodynamics initiative
(CIG), through the National Science Foundation under Awards
No.~EAR-0949446 and EAR-1550901 and The University of California -- Davis.

D.~Davydov was supported by the European Research Council (ERC) through the Advanced Grant 289049 MOCOPOLY and the Competence Network for Technical and Scientific High Performance Computing in Bavaria (KONWIHR).

T.~Heister was partially supported by the Computational Infrastructure in
Geodynamics initiative (CIG), through the National Science Foundation
under Award No. EAR-0949446 and The University of California -- Davis, and National Science Foundation grant DMS1522191.

M.~Kronbichler was partially supported by the German Research Foundation (DFG)
under the project ``High-order discontinuous Galerkin for the exa-scale''
(ExaDG) within the priority program ``Software for Exascale Computing''
(SPPEXA), grant agreement no.~KR4661/2-1, the Bayerisches Kompetenznetzwerk
f\"ur Technisch-Wissenschaftliches Hoch- und H\"ochstleistungsrechnen
(KONWIHR), and the Gauss Centre for Supercomputing e.V.~by providing computing
time on the GCS Supercomputer SuperMUC at Leibniz Supercomputing Centre (LRZ)
through project id pr83te.

J-P.~Pelteret was supported by the European Research Council (ERC) through the Advanced Grant 289049 MOCOPOLY.

The Interdisciplinary Center for Scientific Computing (IWR) at Heidelberg University has provided
hosting services for the \dealii{} web page and the SVN archive.


\bibliography{paper}{}
\bibliographystyle{abbrv}

\end{document}
